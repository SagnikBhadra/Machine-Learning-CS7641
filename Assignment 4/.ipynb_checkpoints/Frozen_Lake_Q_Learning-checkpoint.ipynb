{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8cf436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map, FrozenLakeEnv\n",
    "\n",
    "from util import provide_scores, adjust_data_structure, show_decisions, tsting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8784c804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4x4\n",
      "Solved in: 10000.0 episodes and 0:00:01.710895 seconds\n",
      "gamma: 0.75 total_eps: 10000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.710895\n",
      "Mean reward: 0.31 - mean eps: 23.172\n",
      "Solved in: 10000.0 episodes and 0:00:01.586840 seconds\n",
      "gamma: 0.75 total_eps: 10000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.586840\n",
      "Mean reward: 0.152 - mean eps: 15.358\n",
      "Solved in: 100000.0 episodes and 0:00:16.837962 seconds\n",
      "gamma: 0.75 total_eps: 100000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:16.837962\n",
      "Mean reward: 0.336 - mean eps: 24.881\n",
      "Solved in: 100000.0 episodes and 0:00:17.820953 seconds\n",
      "gamma: 0.75 total_eps: 100000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:17.820953\n",
      "Mean reward: 0.239 - mean eps: 16.382\n",
      "Solved in: 1000000.0 episodes and 0:06:41.526793 seconds\n",
      "gamma: 0.75 total_eps: 1000000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:06:41.526793\n",
      "Mean reward: 0.454 - mean eps: 29.974\n",
      "Solved in: 1000000.0 episodes and 0:05:46.840794 seconds\n",
      "gamma: 0.75 total_eps: 1000000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:05:46.840794\n",
      "Mean reward: 0.526 - mean eps: 30.563\n",
      "Solved in: 10000.0 episodes and 0:00:01.741867 seconds\n",
      "gamma: 0.9 total_eps: 10000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.741867\n",
      "Mean reward: 0.293 - mean eps: 24.832\n",
      "Solved in: 10000.0 episodes and 0:00:01.850101 seconds\n",
      "gamma: 0.9 total_eps: 10000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.850101\n",
      "Mean reward: 0.637 - mean eps: 38.09\n",
      "Solved in: 100000.0 episodes and 0:00:18.082529 seconds\n",
      "gamma: 0.9 total_eps: 100000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.082529\n",
      "Mean reward: 0.719 - mean eps: 41.339\n",
      "Solved in: 100000.0 episodes and 0:00:16.904971 seconds\n",
      "gamma: 0.9 total_eps: 100000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:16.904971\n",
      "Mean reward: 0.344 - mean eps: 29.633\n",
      "Solved in: 1000000.0 episodes and 0:07:35.622780 seconds\n",
      "gamma: 0.9 total_eps: 1000000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:07:35.622780\n",
      "Mean reward: 0.714 - mean eps: 41.024\n",
      "Solved in: 1000000.0 episodes and 0:06:57.763369 seconds\n",
      "gamma: 0.9 total_eps: 1000000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:06:57.763369\n",
      "Mean reward: 0.389 - mean eps: 27.494\n",
      "Solved in: 10000.0 episodes and 0:00:01.860077 seconds\n",
      "gamma: 0.99 total_eps: 10000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.860077\n",
      "Mean reward: 0.599 - mean eps: 35.878\n",
      "Solved in: 10000.0 episodes and 0:00:01.737563 seconds\n",
      "gamma: 0.99 total_eps: 10000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.737563\n",
      "Mean reward: 0.719 - mean eps: 41.162\n",
      "Solved in: 100000.0 episodes and 0:00:17.724179 seconds\n",
      "gamma: 0.99 total_eps: 100000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:17.724179\n",
      "Mean reward: 0.753 - mean eps: 46.488\n",
      "Solved in: 100000.0 episodes and 0:00:17.801685 seconds\n",
      "gamma: 0.99 total_eps: 100000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:17.801685\n",
      "Mean reward: 0.743 - mean eps: 44.033\n",
      "Solved in: 1000000.0 episodes and 0:09:09.904351 seconds\n",
      "gamma: 0.99 total_eps: 1000000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:09.904351\n",
      "Mean reward: 0.759 - mean eps: 42.69\n",
      "Solved in: 1000000.0 episodes and 0:09:31.983315 seconds\n",
      "gamma: 0.99 total_eps: 1000000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:31.983315\n",
      "Mean reward: 0.731 - mean eps: 44.341\n",
      "Solved in: 10000.0 episodes and 0:00:01.986430 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.986430\n",
      "Mean reward: 0.64 - mean eps: 40.824\n",
      "Solved in: 10000.0 episodes and 0:00:02.017530 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:02.017530\n",
      "Mean reward: 0.746 - mean eps: 45.306\n",
      "Solved in: 100000.0 episodes and 0:00:19.363722 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:19.363722\n",
      "Mean reward: 0.733 - mean eps: 44.832\n",
      "Solved in: 100000.0 episodes and 0:00:18.591789 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.591789\n",
      "Mean reward: 0.0 - mean eps: 100.0\n",
      "Solved in: 1000000.0 episodes and 0:09:21.369154 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.01, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:21.369154\n",
      "Mean reward: 0.741 - mean eps: 45.097\n",
      "Solved in: 1000000.0 episodes and 0:10:09.826405 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.1, dr: 1e-06\n",
      "Iteration: 1000000.0 time: 0:10:09.826405\n",
      "Mean reward: 0.736 - mean eps: 44.115\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved in: 10000.0 episodes and 0:00:16.534614 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 10000.0 time: 0:00:16.534614\n",
      "Mean reward: 0.743 - mean eps: 41.237\n",
      "Solved in: 10000.0 episodes and 0:00:02.269430 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:02.269430\n",
      "Mean reward: 0.728 - mean eps: 44.214\n",
      "Solved in: 10000.0 episodes and 0:00:02.590390 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 10000.0 time: 0:00:02.590390\n",
      "Mean reward: 0.028 - mean eps: 5.207\n",
      "Solved in: 10000.0 episodes and 0:00:02.207249 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:02.207249\n",
      "Mean reward: 0.417 - mean eps: 34.157\n",
      "Solved in: 100000.0 episodes and 0:03:04.199382 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 100000.0 time: 0:03:04.199382\n",
      "Mean reward: 0.743 - mean eps: 42.863\n",
      "Solved in: 100000.0 episodes and 0:01:05.076794 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 100000.0 time: 0:01:05.076794\n",
      "Mean reward: 0.738 - mean eps: 46.138\n",
      "Solved in: 100000.0 episodes and 0:00:53.845901 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 100000.0 time: 0:00:53.845901\n",
      "Mean reward: 0.425 - mean eps: 36.975\n",
      "Solved in: 100000.0 episodes and 0:01:00.408262 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 100000.0 time: 0:01:00.408262\n",
      "Mean reward: 0.745 - mean eps: 45.038\n",
      "Solved in: 1000000.0 episodes and 0:33:19.465535 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 1000000.0 time: 0:33:19.465535\n",
      "Mean reward: 0.739 - mean eps: 43.816\n",
      "Solved in: 1000000.0 episodes and 0:28:39.100172 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 1000000.0 time: 0:28:39.100172\n",
      "Mean reward: 0.723 - mean eps: 45.365\n",
      "Solved in: 1000000.0 episodes and 0:25:12.090604 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 1000000.0 time: 0:25:12.090604\n",
      "Mean reward: 0.725 - mean eps: 41.29\n",
      "Solved in: 1000000.0 episodes and 0:26:24.500696 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 1000000.0 time: 0:26:24.500696\n",
      "Mean reward: 0.772 - mean eps: 43.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbhadra/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/Users/sbhadra/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "/Users/sbhadra/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Discount Rate  Training Episodes  Learning Rate  Decay Rate  Reward  \\\n",
      "0          0.9999            10000.0           0.10     0.00100   0.743   \n",
      "1          0.9999            10000.0           0.10     0.00001   0.728   \n",
      "2          0.9999            10000.0           0.01     0.00100   0.028   \n",
      "3          0.9999            10000.0           0.01     0.00001   0.417   \n",
      "4          0.9999           100000.0           0.10     0.00100   0.743   \n",
      "5          0.9999           100000.0           0.10     0.00001   0.738   \n",
      "6          0.9999           100000.0           0.01     0.00100   0.425   \n",
      "7          0.9999           100000.0           0.01     0.00001   0.745   \n",
      "8          0.9999          1000000.0           0.10     0.00100   0.739   \n",
      "9          0.9999          1000000.0           0.10     0.00001   0.723   \n",
      "10         0.9999          1000000.0           0.01     0.00100   0.725   \n",
      "11         0.9999          1000000.0           0.01     0.00001   0.772   \n",
      "\n",
      "     Time Spent  \n",
      "0     16.534614  \n",
      "1      2.269430  \n",
      "2      2.590390  \n",
      "3      2.207249  \n",
      "4    184.199382  \n",
      "5     65.076794  \n",
      "6     53.845901  \n",
      "7     60.408262  \n",
      "8   1999.465535  \n",
      "9   1719.100172  \n",
      "10  1512.090604  \n",
      "11  1584.500696  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16x16\n",
      "Solved in: 10000.0 episodes and 0:00:01.900262 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 10000.0 time: 0:00:01.900262\n",
      "Mean reward: 0.0 - mean eps: 2.987\n",
      "Solved in: 10000.0 episodes and 0:00:01.125488 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:01.125488\n",
      "Mean reward: 0.0 - mean eps: 2.932\n",
      "Solved in: 10000.0 episodes and 0:00:01.896871 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 10000.0 time: 0:00:01.896871\n",
      "Mean reward: 0.0 - mean eps: 2.978\n",
      "Solved in: 10000.0 episodes and 0:00:01.155424 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:01.155424\n",
      "Mean reward: 0.0 - mean eps: 3.033\n",
      "Solved in: 100000.0 episodes and 0:00:18.422587 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 100000.0 time: 0:00:18.422587\n",
      "Mean reward: 0.0 - mean eps: 3.085\n",
      "Solved in: 100000.0 episodes and 0:00:14.213226 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 100000.0 time: 0:00:14.213226\n",
      "Mean reward: 0.0 - mean eps: 3.098\n",
      "Solved in: 100000.0 episodes and 0:00:18.701192 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 100000.0 time: 0:00:18.701192\n",
      "Mean reward: 0.0 - mean eps: 2.968\n",
      "Solved in: 100000.0 episodes and 0:00:14.065538 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 100000.0 time: 0:00:14.065538\n",
      "Mean reward: 0.0 - mean eps: 3.022\n",
      "Solved in: 1000000.0 episodes and 0:02:55.933024 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.1, dr: 0.001\n",
      "Iteration: 1000000.0 time: 0:02:55.933024\n",
      "Mean reward: 0.0 - mean eps: 3.011\n",
      "Solved in: 1000000.0 episodes and 0:03:07.826532 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.1, dr: 1e-05\n",
      "Iteration: 1000000.0 time: 0:03:07.826532\n",
      "Mean reward: 0.0 - mean eps: 3.122\n",
      "Solved in: 1000000.0 episodes and 0:03:12.428932 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.01, dr: 0.001\n",
      "Iteration: 1000000.0 time: 0:03:12.428932\n",
      "Mean reward: 0.0 - mean eps: 3.021\n",
      "Solved in: 1000000.0 episodes and 0:03:05.280879 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 lr: 0.01, dr: 1e-05\n",
      "Iteration: 1000000.0 time: 0:03:05.280879\n",
      "Mean reward: 0.0 - mean eps: 3.058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "    Discount Rate  Training Episodes  Learning Rate  Decay Rate  Reward  \\\n",
      "0          0.9999            10000.0           0.10     0.00100     0.0   \n",
      "1          0.9999            10000.0           0.10     0.00001     0.0   \n",
      "2          0.9999            10000.0           0.01     0.00100     0.0   \n",
      "3          0.9999            10000.0           0.01     0.00001     0.0   \n",
      "4          0.9999           100000.0           0.10     0.00100     0.0   \n",
      "5          0.9999           100000.0           0.10     0.00001     0.0   \n",
      "6          0.9999           100000.0           0.01     0.00100     0.0   \n",
      "7          0.9999           100000.0           0.01     0.00001     0.0   \n",
      "8          0.9999          1000000.0           0.10     0.00100     0.0   \n",
      "9          0.9999          1000000.0           0.10     0.00001     0.0   \n",
      "10         0.9999          1000000.0           0.01     0.00100     0.0   \n",
      "11         0.9999          1000000.0           0.01     0.00001     0.0   \n",
      "\n",
      "    Time Spent  \n",
      "0     1.900262  \n",
      "1     1.125488  \n",
      "2     1.896871  \n",
      "3     1.155424  \n",
      "4    18.422587  \n",
      "5    14.213226  \n",
      "6    18.701192  \n",
      "7    14.065538  \n",
      "8   175.933024  \n",
      "9   187.826532  \n",
      "10  192.428932  \n",
      "11  185.280879  \n"
     ]
    }
   ],
   "source": [
    "def test_policy(env, policy, n_epoch=1000):\n",
    "    rewards = []\n",
    "    episode_counts = []\n",
    "    for i in range(n_epoch):\n",
    "        current_state = env.reset()\n",
    "        ep = 0\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        while not done and ep < 10000:\n",
    "            ep += 1\n",
    "            act = int(policy[current_state])\n",
    "            new_state, reward, done, _ = env.step(act)\n",
    "            episode_reward += reward\n",
    "            current_state = new_state\n",
    "        rewards.append(episode_reward)\n",
    "        episode_counts.append(ep)\n",
    "    \n",
    "    # all done\n",
    "    mean_reward = sum(rewards)/len(rewards)\n",
    "    mean_eps = sum(episode_counts)/len(episode_counts)\n",
    "    return mean_reward, mean_eps, rewards, episode_counts\n",
    "\n",
    "def q_learning(env, discount=0.9, total_episodes=1e5, alpha=0.1, decay_rate=None,\n",
    "               min_epsilon=0.01):\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    number_of_states = env.observation_space.n\n",
    "    number_of_actions = env.action_space.n\n",
    "    \n",
    "    qtable = np.zeros((number_of_states, number_of_actions))\n",
    "    learning_rate = alpha\n",
    "    gamma = discount\n",
    "\n",
    "    # exploration parameter\n",
    "    epsilon = 1.0\n",
    "    max_epsilon = 1.0\n",
    "    min_epsilon = 0.01\n",
    "    \n",
    "    if not decay_rate:\n",
    "        decay_rate = 1./total_episodes\n",
    "    \n",
    "    rewards = []\n",
    "    for episode in range(int(total_episodes)):\n",
    "        # reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "\n",
    "            # choose an action a in the corrent world state\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            # if greater than epsilon --> exploit\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                b = qtable[state, :]\n",
    "                action = np.random.choice(np.where(b == b.max())[0])\n",
    "#                 action = np.argmax(qtable[state, :])\n",
    "            # else choose exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # take action (a) and observe the outcome state (s') and reward (r)    \n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            # update Q(s,a) := Q(s,a) + lr [R(s,a) + gamma * max(Q (s', a') - Q(s,a))]\n",
    "            if not done:\n",
    "                qtable[state, action] = qtable[state, action] + learning_rate*(reward + gamma*np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "            else:\n",
    "                qtable[state, action] = qtable[state,action] + learning_rate*(reward - qtable[state,action])\n",
    "\n",
    "            # change state\n",
    "            state = new_state\n",
    "\n",
    "            # is it Done\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # reduce epsilon \n",
    "        rewards.append(total_reward)\n",
    "        epsilon = max(max_epsilon -  decay_rate * episode, min_epsilon) \n",
    "    #     print (epsilon)\n",
    "    \n",
    "    end = timer()\n",
    "    time_spent = timedelta(seconds=end-start)\n",
    "    print(\"Solved in: {} episodes and {} seconds\".format(total_episodes, time_spent))\n",
    "    return np.argmax(qtable, axis=1), total_episodes, time_spent, qtable, rewards\n",
    "\n",
    "def train_and_test_q_learning(env, discount=[0.9], total_episodes=[1e5], alphas=[0.1], decay_rates=[0.01], mute=False):\n",
    "    \n",
    "    min_epsilon = 0.01\n",
    "    \n",
    "    q_dict = {}\n",
    "    for dis in discount:\n",
    "        q_dict[dis] = {}\n",
    "        for eps in total_episodes:\n",
    "            q_dict[dis][eps] = {}\n",
    "            for alpha in alphas:\n",
    "                q_dict[dis][eps][alpha] = {}\n",
    "                for dr in decay_rates:\n",
    "                    q_dict[dis][eps][alpha][dr] = {}\n",
    "                    \n",
    "                    # run q_learning\n",
    "                    q_policy, q_solve_iter, q_solve_time, q_table, rewards = q_learning(env, dis, eps, alpha, dr, min_epsilon)\n",
    "                    q_mrews, q_meps, _, __ = test_policy(env, q_policy)\n",
    "                    q_dict[dis][eps][alpha][dr][\"mean_reward\"] = q_mrews\n",
    "                    q_dict[dis][eps][alpha][dr][\"mean_eps\"] = q_meps\n",
    "                    q_dict[dis][eps][alpha][dr][\"q-table\"] = q_table\n",
    "                    q_dict[dis][eps][alpha][dr][\"rewards\"] = rewards \n",
    "                    q_dict[dis][eps][alpha][dr][\"iteration\"] = q_solve_iter\n",
    "                    q_dict[dis][eps][alpha][dr][\"time_spent\"] = q_solve_time\n",
    "                    q_dict[dis][eps][alpha][dr][\"policy\"] = q_policy\n",
    "                    if not mute:\n",
    "                        print(\"gamma: {} total_eps: {} lr: {}, dr: {}\".format(dis, eps, alpha, dr))\n",
    "                        print(\"Iteration: {} time: {}\".format(q_solve_iter, q_solve_time))\n",
    "                        print(\"Mean reward: {} - mean eps: {}\".format(q_mrews, q_meps))\n",
    "    return q_dict\n",
    "\n",
    "def map_discretize(the_map):\n",
    "    size = len(the_map)\n",
    "    dis_map = np.zeros((size,size))\n",
    "    for i, row in enumerate(the_map):\n",
    "        for j, loc in enumerate(row):\n",
    "            if loc == \"S\":\n",
    "                dis_map[i, j] = 0\n",
    "            elif loc == \"F\":\n",
    "                dis_map[i, j] = 0\n",
    "            elif loc == \"H\":\n",
    "                dis_map[i, j] = -1\n",
    "            elif loc == \"G\":\n",
    "                dis_map[i, j] = 1\n",
    "    return dis_map\n",
    "\n",
    "\n",
    "def policy_numpy(policy):\n",
    "    size = int(np.sqrt(len(policy)))\n",
    "    pol = np.asarray(policy)\n",
    "    pol = pol.reshape((size, size))\n",
    "    return pol\n",
    "\n",
    "\n",
    "def see_policy(map_size, policy):\n",
    "    map_name = str(map_size)+\"x\"+str(map_size)\n",
    "    data = map_discretize(MAPS[map_name])\n",
    "    np_pol = policy_numpy(policy)\n",
    "    plt.imshow(data, interpolation=\"nearest\")\n",
    "\n",
    "    for i in range(np_pol[0].size):\n",
    "        for j in range(np_pol[0].size):\n",
    "            arrow = '\\u2190'\n",
    "            if np_pol[i, j] == 1:\n",
    "                arrow = '\\u2193'\n",
    "            elif np_pol[i, j] == 2:\n",
    "                arrow = '\\u2192'\n",
    "            elif np_pol[i, j] == 3:\n",
    "                arrow = '\\u2191'\n",
    "            text = plt.text(j, i, arrow,\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "    plt.show()\n",
    "\n",
    "def dict_to_df(the_dict):\n",
    "    the_df = pd.DataFrame(columns=[\"Discount Rate\", \"Training Episodes\", \"Learning Rate\", \n",
    "                                   \"Decay Rate\", \"Reward\", \"Time Spent\"])\n",
    "    for dis in the_dict:\n",
    "        for eps in the_dict[dis]:\n",
    "            for lr in the_dict[dis][eps]:\n",
    "                for dr in the_dict[dis][eps][lr]:\n",
    "                    rew = the_dict[dis][eps][lr][dr][\"mean_reward\"]\n",
    "                    time_spent = the_dict[dis][eps][lr][dr][\"time_spent\"].total_seconds()\n",
    "                    dic = {\"Discount Rate\": dis, \"Training Episodes\": eps, \"Learning Rate\":lr, \n",
    "                           \"Decay Rate\":dr, \"Reward\": rew, \"Time Spent\": time_spent}\n",
    "                    the_df = the_df.append(dic, ignore_index=True)\n",
    "    return the_df\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(44)\n",
    "    sixteen = generate_random_map(16)\n",
    "    np.random.seed(44)\n",
    "    tvelve = generate_random_map(12)\n",
    "    MAPS = {\n",
    "        \"4x4\": [\n",
    "            \"SFFF\",\n",
    "            \"FHFH\",\n",
    "            \"FFFH\",\n",
    "            \"HFFG\"\n",
    "        ],\n",
    "        \"8x8\": [\n",
    "            \"SFFFFFFF\",\n",
    "            \"FFFFFFFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FFFFFHFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FHHFFFHF\",\n",
    "            \"FHFFHFHF\",\n",
    "            \"FFFHFFFG\"\n",
    "        ],\n",
    "        \"12x12\": tvelve,\n",
    "        \"16x16\": sixteen\n",
    "    }\n",
    "    \n",
    "    print(\"4x4\")\n",
    "\n",
    "    env = gym.make('FrozenLake-v1')\n",
    "    episodes = [1e4, 1e5, 1e6]\n",
    "    decays = [1e-6]\n",
    "\n",
    "    q_dict = train_and_test_q_learning(env, discount=[0.75, 0.9, 0.99, 0.9999], total_episodes=episodes,\n",
    "                              alphas=[0.01, 0.1], decay_rates=decays)\n",
    "    \n",
    "    \n",
    "    pol = q_dict[0.99][int(1e6)][0.1][1e-06]['policy']\n",
    "    see_policy(4, pol)\n",
    "    \n",
    "    episodes = [1e4, 1e5, 1e6]\n",
    "    decays = [1e-3, 1e-5]\n",
    "    q_dict = train_and_test_q_learning(env, discount= [0.9999], total_episodes=episodes,\n",
    "                              alphas=[0.1, 0.01], decay_rates=decays)\n",
    "    \n",
    "    rews = q_dict[0.9999][int(1e6)][0.1][1e-03]['rewards']\n",
    "    run = 1000\n",
    "    rew_running = running_mean(rews, run)\n",
    "    indices = [i+run for i in list(range(len(rew_running)))]\n",
    "    sns.lineplot(np.log10(indices), rew_running)\n",
    "    \n",
    "    rews = q_dict[0.9999][int(1e6)][0.01][1e-03]['rewards']\n",
    "    run = 1000\n",
    "    rew_running = running_mean(rews, run)\n",
    "    indices = [i+run for i in list(range(len(rew_running)))]\n",
    "    sns.lineplot(np.log10(indices), rew_running)\n",
    "    \n",
    "    rews = q_dict[0.9999][int(1e6)][0.01][1e-05]['rewards']\n",
    "    run = 1000\n",
    "    rew_running = running_mean(rews, run)\n",
    "    indices = [i+run for i in list(range(len(rew_running)))]\n",
    "    sns.lineplot(np.log10(indices), rew_running)\n",
    "    \n",
    "    \n",
    "    \n",
    "    q4 = dict_to_df(q_dict)\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    pl = sns.lineplot(x=\"Training Episodes\", y=\"Reward\", data=q4)\n",
    "    pl.figure.set_figwidth(12)\n",
    "    pl.figure.set_figheight(8)\n",
    "    \n",
    "    print(q4)\n",
    "    \n",
    "    pol = q_dict[0.9999][int(1e6)][0.01][1e-03]['policy']\n",
    "    see_policy(4, pol)\n",
    "    \n",
    "    \n",
    "    print(\"16x16\")\n",
    "    \n",
    "    env = FrozenLakeEnv(desc=MAPS[\"16x16\"])\n",
    "    episodes = [1e4, 1e5, 1e6]\n",
    "    decays = [1e-3, 1e-5]\n",
    "    q_dict16 = train_and_test_q_learning(env, discount= [0.9999], total_episodes=episodes,\n",
    "                              alphas=[0.1, 0.01], decay_rates=decays)\n",
    "    \n",
    "    pol = q_dict16[0.9999][int(1e6)][0.1][1e-05]['policy']\n",
    "    see_policy(16, pol)\n",
    "    \n",
    "    print((q_dict16[0.9999][int(1e6)][0.1][1e-05]['q-table'] > 0).any())\n",
    "    \n",
    "    print(dict_to_df(q_dict16))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4x4\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.678250 seconds\n",
      "gamma: 0.75 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.678250\n",
      "Mean score: 0.16 - mean change_instance: 17.3\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.861624 seconds\n",
      "gamma: 0.75 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.861624\n",
      "Mean score: 0.097 - mean change_instance: 9.831\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.566168 seconds\n",
      "gamma: 0.75 total_eps: 100000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.566168\n",
      "Mean score: 0.217 - mean change_instance: 19.672\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.362480 seconds\n",
      "gamma: 0.75 total_eps: 100000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.362480\n",
      "Mean score: 0.079 - mean change_instance: 10.56\n",
      "Solved in: 1000000.0 complete_iterations and 0:06:59.725665 seconds\n",
      "gamma: 0.75 total_eps: 1000000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:06:59.725665\n",
      "Mean score: 0.434 - mean change_instance: 28.506\n",
      "Solved in: 1000000.0 complete_iterations and 0:05:43.968239 seconds\n",
      "gamma: 0.75 total_eps: 1000000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:05:43.968239\n",
      "Mean score: 0.282 - mean change_instance: 20.58\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.922783 seconds\n",
      "gamma: 0.9 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.922783\n",
      "Mean score: 0.462 - mean change_instance: 30.388\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.853851 seconds\n",
      "gamma: 0.9 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.853851\n",
      "Mean score: 0.626 - mean change_instance: 40.132\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.622415 seconds\n",
      "gamma: 0.9 total_eps: 100000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.622415\n",
      "Mean score: 0.526 - mean change_instance: 30.839\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.540809 seconds\n",
      "gamma: 0.9 total_eps: 100000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.540809\n",
      "Mean score: 0.219 - mean change_instance: 15.531\n",
      "Solved in: 1000000.0 complete_iterations and 0:08:12.194712 seconds\n",
      "gamma: 0.9 total_eps: 1000000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:08:12.194712\n",
      "Mean score: 0.741 - mean change_instance: 42.413\n",
      "Solved in: 1000000.0 complete_iterations and 0:07:06.858114 seconds\n",
      "gamma: 0.9 total_eps: 1000000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:07:06.858114\n",
      "Mean score: 0.519 - mean change_instance: 31.121\n",
      "Solved in: 10000.0 complete_iterations and 0:00:02.066733 seconds\n",
      "gamma: 0.99 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:02.066733\n",
      "Mean score: 0.491 - mean change_instance: 34.319\n",
      "Solved in: 10000.0 complete_iterations and 0:00:02.120753 seconds\n",
      "gamma: 0.99 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:02.120753\n",
      "Mean score: 0.725 - mean change_instance: 44.879\n",
      "Solved in: 100000.0 complete_iterations and 0:00:23.136293 seconds\n",
      "gamma: 0.99 total_eps: 100000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:23.136293\n",
      "Mean score: 0.758 - mean change_instance: 42.833\n",
      "Solved in: 100000.0 complete_iterations and 0:00:23.758933 seconds\n",
      "gamma: 0.99 total_eps: 100000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:23.758933\n",
      "Mean score: 0.638 - mean change_instance: 40.72\n",
      "Solved in: 1000000.0 complete_iterations and 0:09:22.567314 seconds\n",
      "gamma: 0.99 total_eps: 1000000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:22.567314\n",
      "Mean score: 0.762 - mean change_instance: 43.932\n",
      "Solved in: 1000000.0 complete_iterations and 0:09:01.930377 seconds\n",
      "gamma: 0.99 total_eps: 1000000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:01.930377\n",
      "Mean score: 0.728 - mean change_instance: 43.318\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.936628 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.936628\n",
      "Mean score: 0.373 - mean change_instance: 29.904\n",
      "Solved in: 10000.0 complete_iterations and 0:00:01.884659 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 10000.0 time: 0:00:01.884659\n",
      "Mean score: 0.717 - mean change_instance: 45.813\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.364613 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.364613\n",
      "Mean score: 0.751 - mean change_instance: 44.434\n",
      "Solved in: 100000.0 complete_iterations and 0:00:18.662776 seconds\n",
      "gamma: 0.9999 total_eps: 100000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 100000.0 time: 0:00:18.662776\n",
      "Mean score: 0.0 - mean change_instance: 100.0\n",
      "Solved in: 1000000.0 complete_iterations and 0:09:19.759906 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:19.759906\n",
      "Mean score: 0.72 - mean change_instance: 44.987\n",
      "Solved in: 1000000.0 complete_iterations and 0:09:35.226222 seconds\n",
      "gamma: 0.9999 total_eps: 1000000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-06\n",
      "Iteration: 1000000.0 time: 0:09:35.226222\n",
      "Mean score: 0.535 - mean change_instance: 63.624\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved in: 10000.0 complete_iterations and 0:00:14.643111 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 0.001\n",
      "Iteration: 10000.0 time: 0:00:14.643111\n",
      "Mean score: 0.744 - mean change_instance: 42.494\n",
      "Solved in: 10000.0 complete_iterations and 0:00:02.239847 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.1, speed_of_decrease_instance: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:02.239847\n",
      "Mean score: 0.752 - mean change_instance: 47.047\n",
      "Solved in: 10000.0 complete_iterations and 0:00:03.272462 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 0.001\n",
      "Iteration: 10000.0 time: 0:00:03.272462\n",
      "Mean score: 0.093 - mean change_instance: 7.942\n",
      "Solved in: 10000.0 complete_iterations and 0:00:02.149010 seconds\n",
      "gamma: 0.9999 total_eps: 10000.0 learning_rate: 0.01, speed_of_decrease_instance: 1e-05\n",
      "Iteration: 10000.0 time: 0:00:02.149010\n",
      "Mean score: 0.288 - mean change_instance: 28.234\n"
     ]
    }
   ],
   "source": [
    "def execute_algorithm(game, gamma=0.9, complete_iterations=1e5, learning_rate=0.1, epsilon_decrease=None,\n",
    "               smallest_possible_change=0.01):\n",
    "    \n",
    "    begin = timer()\n",
    "    \n",
    "    x_len = game.observation_space.n\n",
    "    y_len = game.action_space.n\n",
    "    \n",
    "    algo_data_structure = np.zeros((x_len, y_len))\n",
    "\n",
    "    # exploration parameter\n",
    "    change_per_iteration = 1.0\n",
    "    intial_change_allowed = 1.0\n",
    "    smallest_possible_change = 0.01\n",
    "    \n",
    "    if not epsilon_decrease:\n",
    "        epsilon_decrease = 1./complete_iterations\n",
    "    \n",
    "    scores = []\n",
    "    for iteration_i in range(int(complete_iterations)):\n",
    "        # reset the environment\n",
    "        x = game.reset()\n",
    "        one_change = 0\n",
    "        complete = False\n",
    "        cumulative_score = 0\n",
    "        while True:\n",
    "\n",
    "            # choose an y a in the corrent world x\n",
    "            tmp = random.uniform(0,1)\n",
    "\n",
    "            # if greater than change_per_iteration --> exploit\n",
    "            if tmp > change_per_iteration:\n",
    "                current_decision = algo_data_structure[x, :]\n",
    "                y = np.random.choice(np.where(current_decision == current_decision.max())[0])\n",
    "            # else choose exploration\n",
    "            else:\n",
    "                y = game.action_space.sample()\n",
    "\n",
    "            # take y (a) and observe the outcome x (s') and score (r)    \n",
    "            x_prime, score, complete, knowledge = game.step(y)\n",
    "            cumulative_score += score\n",
    "            # update Q(s,a) := Q(s,a) + learning_rate [R(s,a) + gamma * max(Q (s', a') - Q(s,a))]\n",
    "            if not complete:\n",
    "                algo_data_structure[x, y] = algo_data_structure[x, y] + learning_rate*(score + gamma*np.max(algo_data_structure[x_prime, :]) - algo_data_structure[x, y])\n",
    "            else:\n",
    "                algo_data_structure[x, y] = algo_data_structure[x,y] + learning_rate*(score - algo_data_structure[x,y])\n",
    "\n",
    "            # change x\n",
    "            x = x_prime\n",
    "\n",
    "            # is it Done\n",
    "            if complete:\n",
    "                break\n",
    "                \n",
    "        # reduce change_per_iteration \n",
    "        scores.append(cumulative_score)\n",
    "        change_per_iteration = max(intial_change_allowed -  epsilon_decrease * iteration_i, smallest_possible_change) \n",
    "    \n",
    "    finish = timer()\n",
    "    complexity_length = timedelta(seconds=finish-begin)\n",
    "    print(\"Solved in: {} complete_iterations and {} seconds\".format(complete_iterations, complexity_length))\n",
    "\n",
    "    return np.argmax(algo_data_structure, axis=1), complete_iterations, complexity_length, algo_data_structure, scores\n",
    "\n",
    "def run_algorithm_iteration(game, gamma=[0.9], complete_iterations=[1e5], learning_rates=[0.1], speed_of_decrease=[0.01], mute=False):\n",
    "    \n",
    "    smallest_possible_change = 0.01\n",
    "    \n",
    "    algorithm_matrix = {}\n",
    "    for gamma_instance in gamma:\n",
    "        algorithm_matrix[gamma_instance] = {}\n",
    "        for change_instance in complete_iterations:\n",
    "            algorithm_matrix[gamma_instance][change_instance] = {}\n",
    "            for learning_rate in learning_rates:\n",
    "                algorithm_matrix[gamma_instance][change_instance][learning_rate] = {}\n",
    "                for speed_of_decrease_instance in speed_of_decrease:\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance] = {}\n",
    "                    \n",
    "                    # index execute_algorithm\n",
    "                    algorithm_decision, total_num_of_iterations, total_num_of_seconds_taken, algo_data_structure, scores = execute_algorithm(game, gamma_instance, change_instance, learning_rate, speed_of_decrease_instance, smallest_possible_change)\n",
    "                    algorithm_average_score, algorithm_average_episodes, tmp1, tmp2 = tsting(game, algorithm_decision)\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"mean_reward\"] = algorithm_average_score\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"mean_eps\"] = algorithm_average_episodes\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"q-table\"] = algo_data_structure\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"scores\"] = scores \n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"iteration\"] = total_num_of_iterations\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"complexity_length\"] = total_num_of_seconds_taken\n",
    "                    algorithm_matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"policy\"] = algorithm_decision\n",
    "                    if not mute:\n",
    "                        print(\"gamma: {} total_eps: {} learning_rate: {}, speed_of_decrease_instance: {}\".format(gamma_instance, change_instance, learning_rate, speed_of_decrease_instance))\n",
    "                        print(\"Iteration: {} time: {}\".format(total_num_of_iterations, total_num_of_seconds_taken))\n",
    "                        print(\"Mean score: {} - mean change_instance: {}\".format(algorithm_average_score, algorithm_average_episodes))\n",
    "    return algorithm_matrix\n",
    "\n",
    "\n",
    "def data_structure(matrix):\n",
    "    matrix_instance = pd.DataFrame(columns=[\"Discount Rate\", \"Training Episodes\", \"Learning Rate\", \n",
    "                                   \"Decay Rate\", \"Reward\", \"Time Spent\"])\n",
    "    for gamma_instance in matrix:\n",
    "        for change_instance in matrix[gamma_instance]:\n",
    "            for learning_rate in matrix[gamma_instance][change_instance]:\n",
    "                for speed_of_decrease_instance in matrix[gamma_instance][change_instance][learning_rate]:\n",
    "                    sco = matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"mean_reward\"]\n",
    "                    complexity_length = matrix[gamma_instance][change_instance][learning_rate][speed_of_decrease_instance][\"complexity_length\"].total_seconds()\n",
    "                    cdr = {\"Discount Rate\": gamma_instance, \"Training Episodes\": change_instance, \"Learning Rate\":learning_rate, \n",
    "                           \"Decay Rate\":speed_of_decrease_instance, \"Reward\": sco, \"Time Spent\": complexity_length}\n",
    "                    matrix_instance = matrix_instance.append(cdr, ignore_index=True)\n",
    "    return matrix_instance\n",
    "\n",
    "def calculate_average(data, index):\n",
    "    cumsum = np.cumsum(np.insert(data, 0, 0)) \n",
    "    return (cumsum[index:] - cumsum[:-index]) / float(index)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(44)\n",
    "    sixteen = generate_random_map(16)\n",
    "    np.random.seed(44)\n",
    "    tvelve = generate_random_map(12)\n",
    "    index = 1000\n",
    "    MAPS = {\n",
    "        \"4x4\": [\n",
    "            \"SFFF\",\n",
    "            \"FHFH\",\n",
    "            \"FFFH\",\n",
    "            \"HFFG\"\n",
    "        ],\n",
    "        \"8x8\": [\n",
    "            \"SFFFFFFF\",\n",
    "            \"FFFFFFFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FFFFFHFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FHHFFFHF\",\n",
    "            \"FHFFHFHF\",\n",
    "            \"FFFHFFFG\"\n",
    "        ],\n",
    "        \"12x12\": tvelve,\n",
    "        \"16x16\": sixteen\n",
    "    }\n",
    "    \n",
    "    print(\"4x4\")\n",
    "\n",
    "    game = gym.make('FrozenLake-v1')\n",
    "    complete_iterations = [1e4, 1e5, 1e6]\n",
    "    speed_of_decrease = [1e-6]\n",
    "\n",
    "    algorithm_matrix = run_algorithm_iteration(game, gamma=[0.75, 0.9, 0.99, 0.9999], complete_iterations=complete_iterations,\n",
    "                              learning_rates=[0.01, 0.1], speed_of_decrease=speed_of_decrease)\n",
    "    \n",
    "    \n",
    "    decisions = algorithm_matrix[0.99][int(1e6)][0.1][1e-06]['policy']\n",
    "    see_policy(4, decisions, MAPS)\n",
    "    \n",
    "    speed_of_decrease = [1e-3, 1e-5]\n",
    "    algorithm_matrix = run_algorithm_iteration(game, gamma= [0.9999], complete_iterations=complete_iterations,\n",
    "                              learning_rates=[0.1, 0.01], speed_of_decrease=speed_of_decrease)\n",
    "    \n",
    "    data = algorithm_matrix[0.9999][int(1e6)][0.1][1e-03]['scores']\n",
    "    trailing_average = calculate_average(data, index)\n",
    "    xes = [i+index for i in list(range(len(trailing_average)))]\n",
    "    sns.lineplot(np.log10(xes), trailing_average)\n",
    "    \n",
    "    data = algorithm_matrix[0.9999][int(1e6)][0.01][1e-03]['scores']\n",
    "    trailing_average = calculate_average(data, index)\n",
    "    xes = [i+index for i in list(range(len(trailing_average)))]\n",
    "    sns.lineplot(np.log10(xes), trailing_average)\n",
    "    \n",
    "    data = algorithm_matrix[0.9999][int(1e6)][0.01][1e-05]['scores']\n",
    "    trailing_average = calculate_average(data, index)\n",
    "    xes = [i+index for i in list(range(len(trailing_average)))]\n",
    "    sns.lineplot(np.log10(xes), trailing_average)\n",
    "    \n",
    "    \n",
    "    \n",
    "    algo_results = data_structure(algorithm_matrix)\n",
    "    pl = sns.lineplot(x=\"Training Episodes\", y=\"Reward\", data=algo_results)\n",
    "    pl.figure.set_figwidth(12)\n",
    "    pl.figure.set_figheight(8)\n",
    "    \n",
    "    print(algo_results)\n",
    "    \n",
    "    decisions = algorithm_matrix[0.9999][int(1e6)][0.01][1e-03]['policy']\n",
    "    see_policy(4, decisions, MAPS)\n",
    "    \n",
    "    \n",
    "    print(\"16x16\")\n",
    "    \n",
    "    game = FrozenLakeEnv(desc=MAPS[\"16x16\"])\n",
    "    complete_iterations = [1e4, 1e5, 1e6]\n",
    "    speed_of_decrease = [1e-3, 1e-5]\n",
    "    algo_results = run_algorithm_iteration(game, gamma= [0.9999], complete_iterations=complete_iterations,\n",
    "                              learning_rates=[0.1, 0.01], speed_of_decrease=speed_of_decrease)\n",
    "    \n",
    "    decisions = algo_results[0.9999][int(1e6)][0.1][1e-05]['policy']\n",
    "    see_policy(16, decisions, MAPS)\n",
    "    \n",
    "    print((algo_results[0.9999][int(1e6)][0.1][1e-05]['q-table'] > 0).any())\n",
    "    \n",
    "    print(data_structure(algo_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792b858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
