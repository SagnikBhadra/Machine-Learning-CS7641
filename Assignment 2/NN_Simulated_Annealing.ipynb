{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1766a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import mlrose_hiive\n",
    "from mlrose_hiive import ExpDecay\n",
    "from functools import partial\n",
    "import timeit\n",
    "from util import evaluate_data, graph_LC, graph_C, normalize_data, create_stratified_data, prepare_data, preprocess_ufc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf54c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Annealing\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Randimized Hill Climb Time:  3330.886008754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       315\n",
      "           1       0.91      0.92      0.91       403\n",
      "           2       0.92      0.88      0.90       282\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      " samples avg       0.91      0.91      0.91      1000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1262\n",
      "           1       0.89      0.91      0.90      1610\n",
      "           2       0.89      0.89      0.89      1128\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      4000\n",
      "   macro avg       0.90      0.90      0.90      4000\n",
      "weighted avg       0.90      0.90      0.90      4000\n",
      " samples avg       0.90      0.90      0.90      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def testing(output, input_test_set, output_test_set, input_train_set, output_train_set):\n",
    "    predictions = output[3].predict(input_test_set)\n",
    "    print(classification_report(pd.get_dummies(output_test_set.values.ravel()).values, predictions))\n",
    "    \n",
    "    train_predictions = output[3].predict(input_train_set)\n",
    "    print(classification_report(pd.get_dummies(output_train_set.values.ravel()).values, train_predictions))\n",
    "\n",
    "def wine_dataset():\n",
    "    target_feature = \"class\"\n",
    "    mean = \"weighted\"\n",
    "    weighting = \"f1_weighted\"\n",
    "    hyperparameter = \"hidden_layer_sizes\"\n",
    "    cross_validation_splitter = 10\n",
    "    parallel = -1\n",
    "    scroing = partial(f1_score, average=mean)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    wine_dataset = pd.read_csv(\"wine_dataset.csv\")\n",
    "\n",
    "\n",
    "    target = wine_dataset[target_feature]\n",
    "    wine_dataset = normalize_data(wine_dataset)\n",
    "    wine_dataset[target_feature] = target\n",
    "    \n",
    "    in_sample, out_of_sample = create_stratified_data(target_feature, wine_dataset)\n",
    "\n",
    "    output_train_set, input_train_set, output_test_set, input_test_set = prepare_data(in_sample, out_of_sample, target_feature)\n",
    "    \n",
    "    \n",
    "    hyperparameter_tuning = ({\n",
    "      'schedule': [ExpDecay(1),ExpDecay(10),ExpDecay(25),ExpDecay(50)],\n",
    "      'learning_rate': [0.0001, 0.001, 0.01],\n",
    "      'activation': [mlrose_hiive.neural.activation.relu],\n",
    "      'max_iters': [10000]\n",
    "    })\n",
    "    \n",
    "    print('Simulated Annealing')\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    neural_network_simulated_annealing = mlrose_hiive.NNGSRunner(x_train=input_train_set,\n",
    "                         y_train=pd.get_dummies(output_train_set.values.ravel()).values,\n",
    "                         x_test=input_test_set,\n",
    "                         y_test=pd.get_dummies(output_test_set.values.ravel()).values,\n",
    "                         experiment_name='nn_test',\n",
    "                         seed=10,\n",
    "                         output_directory=\"./simulated_annealing\",\n",
    "                         hidden_layer_sizes=[[60,60]],                             \n",
    "                         algorithm=mlrose_hiive.algorithms.sa.simulated_annealing,\n",
    "                         grid_search_parameters=hyperparameter_tuning,\n",
    "                         grid_search_scorer_method=scroing,\n",
    "                         iteration_list=[10000],\n",
    "                         n_jobs=-2)\n",
    "\n",
    "    output = neural_network_simulated_annealing.run()\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    print('Randimized Hill Climb Time: ', stop - start)  \n",
    "    \n",
    "    testing(output, input_test_set, output_test_set, input_train_set, output_train_set)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    wine_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8738c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
